# -*- coding: utf-8 -*-
"""custchurnwithnewdata.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/179Vk8JzRptmESljs6kGMKxppqqv7y5rr
"""

# Importing the essential Libraries
import pandas as pd
import numpy as np

# Reading the Dataset
df = pd.read_csv(r'C:\pythoncustchurnprednewd\Customer-Churn-Records.csv')


df.head()

df.shape

df.columns

df.dtypes

# Printing Unique Values of the categorical variables
print(df['Geography'].unique())
print(df['Gender'].unique())
print(df['NumOfProducts'].unique())
print(df['HasCrCard'].unique())
print(df['IsActiveMember'].unique())
print(df['Complain'].unique())
print(df['Card Type'].unique())

# Checking if there are null values or not
df.isnull().sum()

df.describe()

# Including only Potential Predictors as independent varibles
final_dataset = df[['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited', 'Complain', 'Satisfaction Score', 'Card Type', 'Point Earned']]

final_dataset.head()

# Converting the categorical variables into numerical and avoiding Dummy Varibale Trap
final_dataset = pd.get_dummies(final_dataset, drop_first=True)

final_dataset.head()

import seaborn as sns

sns.pairplot(final_dataset)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

# Plotting The Correlations between all the features
corrmat = final_dataset.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(20,20))
sns.heatmap(final_dataset[top_corr_features].corr(), annot=True, cmap='RdYlGn')

final_dataset.head()

# Splitting the Dataset into Dependent and Independent Variables
X = final_dataset.iloc[:, [0,1,2,3,4,5,6,7,9,10,11,12,13,14,15]]
y = final_dataset.iloc[:, 8].values

X.head()

y

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import ExtraTreesRegressor

# Split dataset into training, validation, and holdout sets
X_temp, X_holdout, y_temp, y_holdout = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)

"""Random Forest Classifier"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import ExtraTreesRegressor

# Split dataset into training, validation, and holdout sets
X_temp, X_holdout, y_temp, y_holdout = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)

# Standardize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_valid = scaler.transform(X_valid)
X_holdout = scaler.transform(X_holdout)

# Calculate feature importance
model = ExtraTreesRegressor()
model.fit(X, y)

# Print feature importance scores
print("Feature Importance:")
print(model.feature_importances_)

# Train the Random Forest Classification model
rf_classifier = RandomForestClassifier(random_state=42)
rf_classifier.fit(X_train, y_train)

# Make predictions on the validation set
y_valid_pred = rf_classifier.predict(X_valid)

# Evaluate the model on the validation set
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
accuracy = accuracy_score(y_valid, y_valid_pred)
conf_matrix = confusion_matrix(y_valid, y_valid_pred)
class_report = classification_report(y_valid, y_valid_pred)

# Print evaluation metrics
print(f"Accuracy: {accuracy}")
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(class_report)

# You can also make predictions on the holdout (test) set for final evaluation
y_holdout_pred = rf_classifier.predict(X_holdout)

"""Logistic Regression"""

final_dataset.head()

# Splitting the Dataset into Dependent and Independent Variables
X = final_dataset.iloc[:, [0,1,2,3,4,5,6,7,9,10,11]]
y = final_dataset.iloc[:, 8].values

X.head()

y

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Create and fit the logistic regression model on the training data
logistic_model = LogisticRegression()
logistic_model.fit(X_train, y_train)

# Make predictions on the validation set
y_valid_pred = logistic_model.predict(X_valid)

# Evaluate the model on the validation set
accuracy = accuracy_score(y_valid, y_valid_pred)
conf_matrix = confusion_matrix(y_valid, y_valid_pred)
class_report = classification_report(y_valid, y_valid_pred)

# Print the evaluation metrics
print(f"Accuracy: {accuracy}")
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(class_report)

# You can also make predictions on the holdout (test) set for final evaluation
y_holdout_pred = logistic_model.predict(X_holdout)

final_dataset.head()

# Splitting the Dataset into Dependent and Independent Variables
X = final_dataset.iloc[:, [0,1,2,3,4,5,6,7,9,10,11]]
y = final_dataset.iloc[:, 8].values

X.head()

y

import xgboost as xgb
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Create and fit the XGBoost model on the training data
xgb_model = xgb.XGBClassifier()
xgb_model.fit(X_train, y_train)

# Make predictions on the validation set
y_valid_pred = xgb_model.predict(X_valid)

# Evaluate the model on the validation set
accuracy = accuracy_score(y_valid, y_valid_pred)
conf_matrix = confusion_matrix(y_valid, y_valid_pred)
class_report = classification_report(y_valid, y_valid_pred)

# Print the evaluation metrics
print(f"Accuracy: {accuracy}")
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(class_report)

# You can also make predictions on the holdout (test) set for final evaluation
y_holdout_pred = xgb_model.predict(X_holdout)

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Create and fit the Decision Tree model on the training data
decision_tree_model = DecisionTreeClassifier()
decision_tree_model.fit(X_train, y_train)

# Make predictions on the validation set
y_valid_pred = decision_tree_model.predict(X_valid)

# Evaluate the model on the validation set
accuracy = accuracy_score(y_valid, y_valid_pred)
conf_matrix = confusion_matrix(y_valid, y_valid_pred)
class_report = classification_report(y_valid, y_valid_pred)

# Print the evaluation metrics
print(f"Accuracy: {accuracy}")
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(class_report)

# You can also make predictions on the holdout (test) set for final evaluation
y_holdout_pred = decision_tree_model.predict(X_holdout)

import pickle
file = open('Customer_Churn_Prediction.pkl', 'wb')
pickle.dump(rf_classifier, file)